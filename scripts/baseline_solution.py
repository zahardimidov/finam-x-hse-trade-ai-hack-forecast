"""
Baseline —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è.

–ü—Ä–æ—Å—Ç–æ–µ —Ä–µ—à–µ–Ω–∏–µ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ML:
- –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –¥–Ω–µ–π
- –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–º–µ–Ω—Ç—É–º–∞
- –≠—Ç–æ baseline –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏
"""

from pathlib import Path

import numpy as np
import pandas as pd


class BaselineSolution:
    """
    Baseline —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö –∏ –º–æ–º–µ–Ω—Ç—É–º–∞

    –õ–æ–≥–∏–∫–∞:
    1. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ –≤—ã—á–∏—Å–ª—è–µ–º –º–æ–º–µ–Ω—Ç—É–º (–∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π)
    2. –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ —Ç—Ä–µ–Ω–¥ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—Å—è (momentum continuation)
    3. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ = —Å–∏–≥–º–æ–∏–¥–∞ –æ—Ç –º–æ–º–µ–Ω—Ç—É–º–∞
    """

    def __init__(self, window_size: int = 5):
        """
        Args:
            window_size: –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–æ–º–µ–Ω—Ç—É–º–∞
        """
        self.window_size = window_size

    def load_data(self, train_candles_path: str,
                  public_test_path: str,
                  private_test_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

        self.train_df = pd.read_csv(train_candles_path)
        self.train_df['begin'] = pd.to_datetime(self.train_df['begin'])

        public_test_df = pd.read_csv(public_test_path)
        public_test_df['begin'] = pd.to_datetime(public_test_df['begin'])

        private_test_df = pd.read_csv(private_test_path)
        private_test_df['begin'] = pd.to_datetime(private_test_df['begin'])

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±–∞ —Ç–µ—Å—Ç–∞
        self.test_df = pd.concat([public_test_df, private_test_df], ignore_index=True)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–æ–º–µ–Ω—Ç—É–º–∞ (–Ω—É–∂–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è)
        self.full_df = pd.concat([self.train_df, self.test_df], ignore_index=True)
        self.full_df = self.full_df.sort_values(['ticker', 'begin'])

        print(f"   ‚úì Train: {len(self.train_df)} —Å—Ç—Ä–æ–∫")
        print(f"   ‚úì Public test:  {len(public_test_df)} —Å—Ç—Ä–æ–∫")
        print(f"   ‚úì Private test: {len(private_test_df)} —Å—Ç—Ä–æ–∫")
        print(f"   ‚úì Total test:   {len(self.test_df)} —Å—Ç—Ä–æ–∫")

    def compute_features(self):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–º–æ–º–µ–Ω—Ç—É–º, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)"""
        print("\nüîß –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        df = self.full_df.copy()

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–∫–µ—Ä–∞–º
        for ticker in df['ticker'].unique():
            mask = df['ticker'] == ticker
            ticker_data = df[mask].copy()

            # 1. –ú–æ–º–µ–Ω—Ç—É–º = –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –∑–∞ window_size –¥–Ω–µ–π
            ticker_data['momentum'] = (
                ticker_data['close'].pct_change(self.window_size)
            )

            # 2. –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å = std –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π –∑–∞ window_size –¥–Ω–µ–π
            ticker_data['volatility'] = (
                ticker_data['close'].pct_change().rolling(self.window_size).std()
            )

            # 3. –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∑–∞ window_size –¥–Ω–µ–π
            ticker_data['ma'] = ticker_data['close'].rolling(self.window_size).mean()

            # 4. –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç MA (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ)
            ticker_data['distance_from_ma'] = (
                (ticker_data['close'] - ticker_data['ma']) / ticker_data['ma']
            )

            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            df.loc[mask, 'momentum'] = ticker_data['momentum'].values
            df.loc[mask, 'volatility'] = ticker_data['volatility'].values
            df.loc[mask, 'ma'] = ticker_data['ma'].values
            df.loc[mask, 'distance_from_ma'] = ticker_data['distance_from_ma'].values

        self.full_df = df
        print("   ‚úì –ü—Ä–∏–∑–Ω–∞–∫–∏ –≤—ã—á–∏—Å–ª–µ–Ω—ã")

    def predict(self):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

        Baseline —Å—Ç—Ä–∞—Ç–µ–≥–∏—è:
        - pred_return = momentum * scaling_factor
        - pred_prob_up = sigmoid(momentum * sensitivity)
        """
        print("\nüéØ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ test –¥–∞–Ω–Ω—ã–µ
        test_data = self.full_df[
            self.full_df['begin'].isin(self.test_df['begin'])
        ].copy()

        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –Ω—É–ª—è–º–∏ (–¥–ª—è –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ –≥–¥–µ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏)
        test_data['momentum'] = test_data['momentum'].fillna(0)
        test_data['volatility'] = test_data['volatility'].fillna(0.01)
        test_data['distance_from_ma'] = test_data['distance_from_ma'].fillna(0)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
        # –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –º–æ–º–µ–Ω—Ç—É–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—Å—è
        # –î–ª—è 1 –¥–Ω—è: momentum * 0.3 (–æ—Å–ª–∞–±–ª—è–µ–º —Å–∏–≥–Ω–∞–ª)
        # –î–ª—è 20 –¥–Ω–µ–π: momentum * 1.0 (–Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç)
        test_data['pred_return_1d'] = test_data['momentum'] * 0.3
        test_data['pred_return_20d'] = test_data['momentum'] * 1.0

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–≥–º–æ–∏–¥—É –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –º–æ–º–µ–Ω—Ç—É–º–∞ –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        def sigmoid(x, sensitivity=10):
            return 1 / (1 + np.exp(-sensitivity * x))

        test_data['pred_prob_up_1d'] = sigmoid(test_data['momentum'], sensitivity=10)
        test_data['pred_prob_up_20d'] = sigmoid(test_data['momentum'], sensitivity=5)

        # Clipping: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0.1, 0.9] –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        test_data['pred_prob_up_1d'] = test_data['pred_prob_up_1d'].clip(0.1, 0.9)
        test_data['pred_prob_up_20d'] = test_data['pred_prob_up_20d'].clip(0.1, 0.9)

        # Clipping: –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑—É–º–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ [-0.2, 0.2]
        test_data['pred_return_1d'] = test_data['pred_return_1d'].clip(-0.2, 0.2)
        test_data['pred_return_20d'] = test_data['pred_return_20d'].clip(-0.5, 0.5)

        self.predictions = test_data

        print(f"   ‚úì –°–æ–∑–¥–∞–Ω–æ {len(self.predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        print(f"\n   üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
        print(f"      –°—Ä–µ–¥–Ω—è—è pred_return_1d:  {test_data['pred_return_1d'].mean():.6f}")
        print(f"      –°—Ä–µ–¥–Ω—è—è pred_return_20d: {test_data['pred_return_20d'].mean():.6f}")
        print(f"      –°—Ä–µ–¥–Ω—è—è pred_prob_up_1d: {test_data['pred_prob_up_1d'].mean():.4f}")
        print(f"      –°—Ä–µ–¥–Ω—è—è pred_prob_up_20d: {test_data['pred_prob_up_20d'].mean():.4f}")

    def save_submission(self, output_path: str = "submission.csv"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ submission —Ñ–∞–π–ª–∞"""
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ submission...")

        submission = self.predictions[[
            'ticker', 'begin',
            'pred_return_1d', 'pred_return_20d',
            'pred_prob_up_1d', 'pred_prob_up_20d'
        ]].copy()

        submission.to_csv(output_path, index=False)

        print(f"   ‚úì Submission —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        print(f"   –°—Ç—Ä–æ–∫: {len(submission)}")
        print(f"\n   üìã –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:")
        print(submission.head(10).to_string(index=False))

    def run(self, train_path: str, public_test_path: str,
            private_test_path: str, output_path: str = "submission.csv"):
        """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω baseline —Ä–µ—à–µ–Ω–∏—è"""
        print("=" * 70)
        print("üöÄ BASELINE –†–ï–®–ï–ù–ò–ï")
        print("=" * 70 + "\n")

        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.load_data(train_path, public_test_path, private_test_path)

        # 2. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.compute_features()

        # 3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        self.predict()

        # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        self.save_submission(output_path)

        print("\n" + "=" * 70)
        print("‚úÖ BASELINE –ì–û–¢–û–í!")
        print("=" * 70)
        print(f"\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print(f"   1. –û—Ü–µ–Ω–∏—Ç–µ –Ω–∞ public:  python scripts/evaluate_submission.py {output_path} public")
        print(f"   2. –û—Ü–µ–Ω–∏—Ç–µ –Ω–∞ private: python scripts/evaluate_submission.py {output_path} private")
        print(f"   3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–æ —Ä–µ—à–µ–Ω–∏–µ –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–Ω—É—é —Ç–æ—á–∫—É –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π")
        print(f"   4. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å ML –º–æ–¥–µ–ª–∏, NLP –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Ç.–¥.")


if __name__ == "__main__":
    baseline = BaselineSolution(window_size=5)

    baseline.run(
        train_path="data/processed/participants/train_candles.csv",
        public_test_path="data/processed/participants/public_test_candles.csv",
        private_test_path="data/processed/participants/private_test_candles.csv",
        output_path="baseline_submission.csv"
    )

