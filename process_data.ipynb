{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e474e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/raw/participants/'\n",
    "\n",
    "train_news = pd.read_csv(data_dir + \"train_news.csv\")\n",
    "train_candles = pd.read_csv(data_dir + 'train_candles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c8e36d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         open   close    high     low  volume       begin ticker  \\\n",
      "20706  1344.0  1335.4  1355.2  1329.6  106126  2020-06-19      T   \n",
      "20707  1336.0  1371.8  1378.4  1250.0  263697  2020-06-22      T   \n",
      "20708  1380.0  1436.2  1456.8  1374.0  394282  2020-06-23      T   \n",
      "\n",
      "       target_return_1d  target_direction_1d  target_return_20d  \\\n",
      "20706          0.027258                    1           0.289951   \n",
      "20707          0.046946                    1           0.290276   \n",
      "20708          0.014761                    1           0.222671   \n",
      "\n",
      "       target_direction_20d  \n",
      "20706                     1  \n",
      "20707                     1  \n",
      "20708                     1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close1</th>\n",
       "      <th>close2</th>\n",
       "      <th>close3</th>\n",
       "      <th>volume1</th>\n",
       "      <th>volume2</th>\n",
       "      <th>volume3</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>target_return_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1335.4</td>\n",
       "      <td>1371.8</td>\n",
       "      <td>1436.2</td>\n",
       "      <td>106126.0</td>\n",
       "      <td>263697.0</td>\n",
       "      <td>394282</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>0.014761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   close1  close2  close3   volume1   volume2  volume3      begin        end  \\\n",
       "0  1335.4  1371.8  1436.2  106126.0  263697.0   394282 2020-06-19 2020-06-23   \n",
       "\n",
       "   target_return_1d  \n",
       "0          0.014761  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_ml_dataset(df: pd.DataFrame,\n",
    "                    ts_cols: list,\n",
    "                    single_cols: list,\n",
    "                    window: int = 5\n",
    "                   ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Формирует датасет для обучения из временного ряда (оптимизированный вариант).\n",
    "    \"\"\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # 0. sanity-check\n",
    "    df['begin'] = pd.to_datetime(df[\"begin\"])\n",
    "\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # 1. временные признаки через shift\n",
    "    for col in ts_cols:\n",
    "        for j in range(window):\n",
    "            out[f\"{col}{j+1}\"] = df[col].shift(window - j - 1)\n",
    "\n",
    "    # 2. begin / end через rolling (используем astype вместо view)\n",
    "    begin_int = df[\"begin\"].astype(\"int64\")\n",
    "    out[\"begin\"] = pd.to_datetime(begin_int.rolling(window).min())\n",
    "    out[\"end\"]   = pd.to_datetime(begin_int.rolling(window).max())\n",
    "\n",
    "    # 3. одноразовые колонки (берем из правого края окна)\n",
    "    for col in single_cols:\n",
    "        if col != \"begin\":\n",
    "            out[col] = df[col]\n",
    "\n",
    "    # 4. убираем первые window-1 строк (NaN)\n",
    "    out = out.iloc[window-1:].reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "# На глаз проверяем работу функции\n",
    "ticker = 'T'\n",
    "mask = train_candles['ticker'] == ticker\n",
    "data = train_candles[mask].copy()\n",
    "print(data.head(3))\n",
    "\n",
    "make_ml_dataset(\n",
    "    data,\n",
    "    ts_cols=['close', 'volume'],\n",
    "    single_cols=['target_return_1d'],\n",
    "    window=3,\n",
    ").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25a62ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timeseries_features(data, window_size_features):\n",
    "    # data - история свечей по отдельному тикеру с колонками из оригинальных файлов\n",
    "    # Добавим фичи из бейзлайна для примера\n",
    "    # Моментум = процентное изменение цены за window_size дней\n",
    "    data['momentum'] = (\n",
    "        data['close'].pct_change(window_size_features)\n",
    "    )\n",
    "\n",
    "    # Волатильность = std доходностей за window_size дней\n",
    "    data['volatility'] = (\n",
    "        data['close'].pct_change().rolling(window_size_features).std()\n",
    "    )\n",
    "    \n",
    "    # Средняя цена за window_size дней\n",
    "    data['ma'] = data['close'].rolling(window_size_features).mean()\n",
    "\n",
    "    # Расстояние от MA (нормализованное)\n",
    "    data['distance_from_ma'] = (\n",
    "        (data['close'] - data['ma']) / data['ma']\n",
    "    )\n",
    "    data['momentum'] = data['momentum'].fillna(0)\n",
    "    data['volatility'] = data['volatility'].fillna(0.01)\n",
    "    data['distance_from_ma'] = data['distance_from_ma'].fillna(0)\n",
    "    data['ma'] = data['ma'].fillna(data['close'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8a7eb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_data(\n",
    "        df,\n",
    "        df_news,\n",
    "        save_dir,\n",
    "        prefix='',\n",
    "        window_size_features=5,\n",
    "        window_size_ravel=5\n",
    "    ):\n",
    "\n",
    "    ts_cols = [\"open\", \"close\", \"high\", \"low\", \"volume\"]\n",
    "\n",
    "    single_cols = [\"begin\", \"ticker\", \"target_return_1d\", \"target_direction_1d\", \n",
    "                \"target_return_20d\", \"target_direction_20d\"]\n",
    "\n",
    "    results = []\n",
    "    df_news['publish_date'] = pd.to_datetime(df_news['publish_date'])\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for ticker, data in tqdm(df.groupby(by='ticker')):\n",
    "        # ================================================================\n",
    "        # 1. Предобработка перед доавблением фичей\n",
    "        # ================================================================\n",
    "        data['begin'] = pd.to_datetime(data['begin'])\n",
    "        data.sort_values(by='begin')\n",
    "        \n",
    "        \n",
    "        # ================================================================\n",
    "        # 2. Добавление фичей до выпрямления\n",
    "        # ================================================================\n",
    "        cols_before = data.columns\n",
    "        data = add_timeseries_features(data, window_size_features)\n",
    "        new_cols = [col for col in data.columns if col not in cols_before]\n",
    "        ts_cols.extend(new_cols)\n",
    "            \n",
    "        # ================================================================\n",
    "        # 4. Выпрямляем\n",
    "        # ================================================================\n",
    "        data = make_ml_dataset(\n",
    "            data,\n",
    "            ts_cols=ts_cols,\n",
    "            single_cols=single_cols,\n",
    "            window=window_size_ravel,\n",
    "        )\n",
    "        # ================================================================\n",
    "        # 5. Добавляем новости\n",
    "        # ================================================================\n",
    "        begin = data['begin']\n",
    "        end = data['end']\n",
    "        \n",
    "        def get_news_on_date(date, ticker):\n",
    "            mask = df_news['publish_date'].dt.date == (date - pd.Timedelta(days=1)) # t-1 по требованиям\n",
    "            news = df_news[mask] # TODO : Добавить фильтрацию по тикерам\n",
    "            titles = news['title'].to_list()\n",
    "            publications = news['publication'].to_list()\n",
    "            return titles, publications\n",
    "            \n",
    "        f = lambda x : get_news_on_date(x, ticker)\n",
    "        data[['titles', 'publications']] = (end.dt.date).apply(f).apply(pd.Series)\n",
    "        \n",
    "        # ================================================================\n",
    "        # 5. Сохраняем в отдельный файл\n",
    "        # ================================================================\n",
    "        path = save_dir + f\"{prefix}{ticker}.csv\"\n",
    "        data.to_csv(path)\n",
    "        \n",
    "        # ================================================================\n",
    "        # 5. Сохраняем все\n",
    "        # ================================================================\n",
    "        data['ticker'] = ticker\n",
    "        results.append(data)\n",
    "\n",
    "    total = pd.concat(results, axis=0)\n",
    "    path = save_dir + f'{prefix}total.csv'\n",
    "    total.to_csv(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4eb5b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:25<00:00,  4.49s/it]\n"
     ]
    }
   ],
   "source": [
    "process_data(\n",
    "    df=train_candles,\n",
    "    df_news=train_news,\n",
    "    save_dir='./data/processed/train/',\n",
    "    window_size_features=5,\n",
    "    window_size_ravel=5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
